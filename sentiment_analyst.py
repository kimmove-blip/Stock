import requests
from bs4 import BeautifulSoup

class SentimentAnalyst:
    def __init__(self):
        # API í‚¤ ì—†ì´ í¬ë¡¤ë§ë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ ì´ˆê¸°í™” ë‚´ìš© ì—†ìŒ
        pass

    def get_news_sentiment(self, code):
        """
        [ìˆ˜ì •ë¨] API ëŒ€ì‹  ë„¤ì´ë²„ ê¸ˆìœµ 'ë‰´ìŠ¤/ê³µì‹œ' íƒ­ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.
        """
        # ë„¤ì´ë²„ ê¸ˆìœµ ì¢…ëª©ë³„ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ URL
        url = f"https://finance.naver.com/item/news_news.nhn?code={code}"
        
        headers = {'User-Agent': 'Mozilla/5.0'}
        
        try:
            res = requests.get(url, headers=headers)
            # ë„¤ì´ë²„ ê¸ˆìœµì€ ê°€ë” ì¸ì½”ë”© ë¬¸ì œê°€ ìˆì–´ euc-krë¡œ ë³€í™˜ í•„ìš”í•  ìˆ˜ ìˆìŒ
            soup = BeautifulSoup(res.content.decode('euc-kr', 'replace'), 'html.parser')
            
            # ë‰´ìŠ¤ ì œëª© ì¶”ì¶œ
            titles = soup.select('.title')
            
            score = 0
            reasons = []
            analyzed_titles = []

            # ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ (ì¡°ê¸ˆ ë” ëŠ˜ë ¸ìŠµë‹ˆë‹¤)
            good_words = ["ìˆ˜ì£¼", "ê³„ì•½", "ìµœëŒ€", "í˜¸ì¬", "ê¸‰ë“±", "ìƒìŠ¹", "í‘ì", "ì„±ì¥", "ëŒíŒŒ", "ê¸°ëŒ€"]
            bad_words = ["ì ì", "í•˜ë½", "ê¸‰ë½", "ì†ì‹¤", "ë°°ì„", "íš¡ë ¹", "ìš°ë ¤", "ì•½ì„¸", "ë‘”í™”", "ë¶ˆì•ˆ"]
            
            for t in titles[:30]: # ìµœê·¼ 15ê°œ ë‰´ìŠ¤ë§Œ ë¶„ì„
                title_text = t.get_text().strip()
                analyzed_titles.append(title_text)
                
                if any(w in title_text for w in good_words):
                    score += 1
                if any(w in title_text for w in bad_words):
                    score -= 1
            
            # ê²°ê³¼ í…ìŠ¤íŠ¸ ìƒì„±
            if score >= 3:
                reasons.append(f"ğŸ”¥ ë‰´ìŠ¤ ë¶„ìœ„ê¸° ì¢‹ìŒ (ê¸ì • í‚¤ì›Œë“œ ìš°ì„¸, ì ìˆ˜: {score})")
            elif score <= -3:
                reasons.append(f"ğŸ¥¶ ë‰´ìŠ¤ ë¶„ìœ„ê¸° ëƒ‰ë­ (ë¶€ì • í‚¤ì›Œë“œ ìš°ì„¸, ì ìˆ˜: {score})")
            else:
                reasons.append(f"ğŸ˜ ë‰´ìŠ¤ ë¶„ìœ„ê¸° ì¤‘ë¦½ (ì ìˆ˜: {score})")
                
            return score, reasons, analyzed_titles
            
        except Exception as e:
            return 0, [f"ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}"], []

    def get_discussion_buzz(self, code):
        """
        ë„¤ì´ë²„ ê¸ˆìœµ ì¢…ëª©í† ë¡ ì‹¤ í¬ë¡¤ë§
        """
        url = f"https://finance.naver.com/item/board.naver?code={code}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        
        try:
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            
            titles = soup.select('td.title a')
            
            buzz_score = 0
            detected_titles = []
            
            # í‚¤ì›Œë“œ ê°ì§€ ë¡œì§
            panic_words = ["í•œê°•", "êµ¬ì¡°ëŒ€", "ë§í–ˆ", "ì†ì ˆ", "ë”í™©ì°¨", "í­ë½", "í•˜ë½", "ë¬¼ë ¤"]
            hope_words = ["ê°€ì¦ˆì•„", "ìƒí•œê°€", "ë–¡ìƒ", "ì¡´ë²„", "ì°¬í‹°", "ìƒìŠ¹", "ìˆ˜ìµ", "ì¶•í•˜"]
            
            for t in titles[:20]:
                text = t.get_text().strip()
                # ì œëª©ì—ì„œ 'ë‹µê¸€' í‘œì‹œ ë“±ì˜ ê³µë°± ì œê±°
                clean_text = " ".join(text.split()) 
                
                if any(w in clean_text for w in panic_words):
                    buzz_score -= 1
                    detected_titles.append(f"ğŸ˜¨ {clean_text}")
                elif any(w in clean_text for w in hope_words):
                    buzz_score += 1
                    detected_titles.append(f"ğŸ¤‘ {clean_text}")
            
            reasons = []
            if buzz_score <= -2: # ê¸°ì¤€ì„ ì¡°ê¸ˆ ë‚®ì¶¤
                reasons.append("ğŸ“‰ í† ë¡ ë°© ê³µí¬/ì‹¤ë§ê° ê°ì§€")
            elif buzz_score >= 2:
                reasons.append("ğŸ“ˆ í† ë¡ ë°© ê¸°ëŒ€ê° ê³ ì¡°")
            else:
                reasons.append("ğŸ’¬ í† ë¡ ë°© ë¶„ìœ„ê¸° ê´€ë§/ì¡ë‹´ ìœ„ì£¼")
                
            return buzz_score, reasons, detected_titles
            
        except Exception as e:
            return 0, [f"í† ë¡ ë°© í¬ë¡¤ë§ ì‹¤íŒ¨: {e}"], []

# --- ì‹¤í–‰ë¶€ ---
if __name__ == "__main__":
    analyst = SentimentAnalyst()
    
    code = "005930" # ì‚¼ì„±ì „ì
    print(f"ğŸ“° ì‚¼ì„±ì „ì({code}) ì„¼í‹°ë©˜íŠ¸ ë¶„ì„ ì‹œì‘...\n")
    
    # 1. ë‰´ìŠ¤ ë¶„ì„ (í¬ë¡¤ë§ ë²„ì „)
    n_score, n_reasons, n_titles = analyst.get_news_sentiment(code)
    print(f"[ë‰´ìŠ¤ ë¶„ì„] ì ìˆ˜: {n_score}")
    print(f"ì§„ë‹¨: {n_reasons[0]}")
    if n_titles:
        print(f"ìµœì‹  í—¤ë“œë¼ì¸: {n_titles[0]} ì™¸ {len(n_titles)-1}ê±´")
    
    print("-" * 30)
    
    # 2. í† ë¡ ë°© ë¶„ì„
    d_score, d_reasons, d_titles = analyst.get_discussion_buzz(code)
    print(f"[í† ë¡ ë°© ë¶„ì„] ì ìˆ˜: {d_score}")
    print(f"ì§„ë‹¨: {d_reasons[0]}")
    
    if d_titles:
        print("\n[ğŸ”¥ ê°ì§€ëœ ê²Œì‹œê¸€]")
        for t in d_titles:
            print(t)
    else:
        print("\n(íŠ¹ì´ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤)")